{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "#                ___________\n",
    "#    ______     /   ____    ____      _          ______\n",
    "#   |  ____|   /   /    INRS    \\    | |        |  ____|\n",
    "#   | |       /   /     Edge     \\   | |        | |\n",
    "#   | |____  /   /    Computing   \\  | |        | |____\n",
    "#   |  ____| \\   \\  Communication /  | |        |  ____|   \n",
    "#   | |       \\   \\   Learning   /   | |        | |\n",
    "#   | |____    \\   \\_____LAB____/    | |_____   | |____\n",
    "#   |______|    \\ ___________        |_______|  |______|\n",
    "#\n",
    "#  Edge Computing, Communication and Learning Lab - INRS University\n",
    "#\n",
    "#  Author: Mobin Vaziri\n",
    "#\n",
    "#  Project: HENNC\n",
    "#  \n",
    "#  Creation Date: 2023-07-08\n",
    "#\n",
    "#  Description:  \n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Run Keras on GPU\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import load_model\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Chen system\n",
    "def chen_system(state, t):\n",
    "    x, y, z = state  # Unpack the state vector\n",
    "    a = 40\n",
    "    b = 3\n",
    "    c = 28\n",
    "    dx = a * (y - x)\n",
    "    dy = (c - a) * x - x * z + c * y\n",
    "    dz = x * y - b * z\n",
    "    return dx, dy, dz  # Derivatives\n",
    "\n",
    "# Number of points\n",
    "num_points = 100000  # Adjust this to change the number of points\n",
    "\n",
    "# Solve the system\n",
    "state0 = [-0.1, 0.5, -0.6]\n",
    "t = np.linspace(0.0, 100.0, num_points)\n",
    "states = odeint(chen_system, state0, t)\n",
    "\n",
    "# Create the dataset\n",
    "X = states[:-1]\n",
    "Y = states[1:]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#input data normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds():\n",
    "   \n",
    "   np.random.seed(42) \n",
    "   python_random.seed(42)\n",
    "   tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc_1 (Dense)                (None, 8)                 32        \n",
      "                                                                 \n",
      " act_1 (Activation)          (None, 8)                 0         \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 3)                 27        \n",
      "                                                                 \n",
      " act_2 (Activation)          (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reset_seeds()\n",
    "\n",
    "# Define the MLP\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, input_dim = 3,  name=\"fc_1\"))\n",
    "\n",
    "model.add(Activation(activation = 'relu', name = \"act_1\"))\n",
    "\n",
    "model.add(Dense(3, name = \"fc_2\"))\n",
    "\n",
    "model.add(Activation(activation = \"linear\", name = \"act_2\"))\n",
    "\n",
    "# Optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = loss_fn, optimizer = opt)\n",
    "\n",
    "# Early Stopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true the pretrained model will be used else the model is going to be trained.\n",
    "pre_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_trained == True:\n",
    "\n",
    "    model = load_model(\"my_model.h5\")\n",
    "\n",
    "else:\n",
    "    # Train the model and store the history\n",
    "    history = model.fit(X_train_scaled, Y_train, validation_data=(X_test_scaled, Y_test), epochs = 300, batch_size=128, verbose=1, callbacks=[callback])\n",
    "\n",
    "    # Plot MSE vs epoch\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model RMSE')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 620us/step\n",
      "625/625 [==============================] - 0s 603us/step\n",
      "            MSE       MAE      RMSE  R2 Score\n",
      "Train  0.000327  0.011742  0.018095  0.999989\n",
      "Test   0.000308  0.011653  0.017547  0.999990\n"
     ]
    }
   ],
   "source": [
    "# Run inference on the training and testing sets\n",
    "Y_train_pred = model.predict(X_train_scaled)\n",
    "Y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
    "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
    "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "train_rmse = sqrt(train_mse)\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "# Calculate R2 Score\n",
    "train_r2 = r2_score(Y_train, Y_train_pred)\n",
    "test_r2 = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "\n",
    "# Calculate the metrics\n",
    "metrics = {\n",
    "    'MSE': [train_mse, test_mse],\n",
    "    'MAE': [train_mae, test_mae],\n",
    "    'RMSE': [train_rmse, test_rmse],\n",
    "    'R2 Score': [train_r2, test_r2]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(metrics, index=['Train', 'Test'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 781us/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of w_1 is (3, 8), w_2 is (8, 3), b_1 is (8,), and b_2 is (3,)\n"
     ]
    }
   ],
   "source": [
    "w_l1 = model.layers[0].get_weights()[0]\n",
    "b_l1 = model.layers[0].get_weights()[1]\n",
    "\n",
    "w_l2 = model.layers[2].get_weights()[0]\n",
    "b_l2 = model.layers[2].get_weights()[1]\n",
    "\n",
    "w_1 = list()\n",
    "b_1 = list()\n",
    "\n",
    "w_2 = list()\n",
    "b_2 = list()\n",
    "\n",
    "for r in range (0, w_l1.shape[0]):\n",
    "    for c in range (0, w_l1.shape[1]):\n",
    "        \n",
    "        w_1.append(w_l1[r][c])\n",
    "\n",
    "w_1 = np.array(w_1)\n",
    "\n",
    "w_1 = w_1.reshape((w_l1.shape[0],w_l1.shape[1]))\n",
    "\n",
    "\n",
    "for r in range (0, w_l2.shape[0]):\n",
    "    for c in range (0, w_l2.shape[1]):\n",
    "        \n",
    "        w_2.append(w_l2[r][c])\n",
    "\n",
    "w_2 = np.array(w_2)\n",
    "\n",
    "w_2 = w_2.reshape((w_l2.shape[0],w_l2.shape[1]))\n",
    "\n",
    "\n",
    "for i in range (0, b_l1.shape[0]):\n",
    "    \n",
    "    b_1.append(b_l1[i])\n",
    "    \n",
    "b_1 = np.array(b_1)\n",
    "\n",
    "b_1 = b_1.reshape(b_l1.shape[0])\n",
    "\n",
    "\n",
    "for i in range (0, b_l2.shape[0]):\n",
    "    \n",
    "    b_2.append(b_l2[i])\n",
    "    \n",
    "b_2 = np.array(b_2)\n",
    "\n",
    "b_2 = b_2.reshape(b_l2.shape[0])\n",
    "\n",
    "print(\"Shape of w_1 is {}, w_2 is {}, b_1 is {}, and b_2 is {}\" .format(w_1.shape, w_2.shape, b_1.shape, b_2.shape))\n",
    "\n",
    "np.savetxt('w_1.txt', w_1, delimiter=' ', fmt=\"%s\")\n",
    "np.savetxt('w_2.txt', w_2, delimiter=' ', fmt=\"%s\")\n",
    "np.savetxt('b_1.txt', b_1, delimiter=' ', fmt=\"%s\")\n",
    "np.savetxt('b_2.txt', b_2, delimiter=' ', fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
